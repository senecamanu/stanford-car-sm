{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Cars using Fast.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!deactivate # if you're using any \n",
    "import os\n",
    "import multiprocessing\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # Change if GPU is more than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from fastai import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './data-kaggle/car_data/'\n",
    "train = 'train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "folders = [f for f in glob.glob(dir + train + \"**/\", recursive=True)]\n",
    "folders.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in range(len(folders)):\n",
    "    curCat = folders[cat]\n",
    "    for r, d, f in os.walk(curCat):\n",
    "        for file in f:\n",
    "            fileName = curCat + file\n",
    "            strToFind = '.jpg'\n",
    "            None if file.find(strToFind) == -1 else files.append(curCat + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = './data-kaggle/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = []\n",
    "file_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_dir + 'names.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        class_names.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_dir + 'anno_train.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=\",\")\n",
    "    for row in csv_reader:\n",
    "        file_data.append([row[0], int(row[2]), int(row[4]), int(row[1]), int(row[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "        \n",
    "    return cv2.resize(image, dim, interpolation = inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "width_less = 0\n",
    "triple_width = 0\n",
    "double_width = 0\n",
    "vertical = 0\n",
    "\n",
    "for i in files:\n",
    "    base_img = cv2.cvtColor(cv2.imread(i), cv2.COLOR_BGR2RGB)\n",
    "    csv_dir = './data-kaggle/'\n",
    "    class_names = []\n",
    "    fs = []\n",
    "    for n in file_data:\n",
    "        if n[0] == i.split('/')[-1]:\n",
    "            fs = n\n",
    "    cropped_img = base_img[fs[1]:fs[2], fs[3]:fs[4]]\n",
    "    cropped_img_resize = image_resize(cropped_img, height = 400)\n",
    "    height, width, _ = cropped_img_resize.shape\n",
    "    name_0 = dir_name_crop.split('.jpg')[0] + '_cropped_0' + '.jpg'\n",
    "    cv2.imwrite(name_0, cropped_img_resize)\n",
    "    \n",
    "    if width > 400 and width > height:\n",
    "        mid_width = int(width / 2 - 200 if width / 2 - 200 >= 0 else width / width)\n",
    "        max_width = int(width - 400 if width >= 400 else width / width)\n",
    "\n",
    "        cropped_1 = cropped_img_resize[0:height, 0:400]\n",
    "        cropped_2 = cropped_img_resize[0:height, mid_width:mid_width + 400]\n",
    "        cropped_3 = cropped_img_resize[0:height, max_width:width]\n",
    "    \n",
    "        dir_name = i.split('/')\n",
    "        dir_name[3] = 'train'\n",
    "        dir_name_crop = ''\n",
    "        \n",
    "        for i in dir_name:\n",
    "            dir_name_crop += (str(i) + '/')\n",
    "            \n",
    "        dir_name_crop = dir_name_crop[:-1]\n",
    "\n",
    "        name_1 = dir_name_crop.split('.jpg')[0] + '_cropped_1' + '.jpg'\n",
    "        name_2 = dir_name_crop.split('.jpg')[0] + '_cropped_2' + '.jpg'\n",
    "        name_3 = dir_name_crop.split('.jpg')[0] + '_cropped_3' + '.jpg'\n",
    "\n",
    "        cv2.imwrite(name_1, cropped_1)\n",
    "        cv2.imwrite(name_2, cropped_2)\n",
    "        cv2.imwrite(name_3, cropped_3)\n",
    "    \n",
    "    print(str(counter + 1) + \" / \" + str(len(files)) + \" have been cropped.\")\n",
    "    counter += 1\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(\n",
    "    do_flip=False, \n",
    "    flip_vert=True, \n",
    "    max_rotate=15.0\n",
    ")\n",
    "\n",
    "num_workers = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data_build** is the function that returns new image bunch,\n",
    "\n",
    "**fit** is the function that run the fitting process,\n",
    "\n",
    "**change_size** is the function that change image bunch sizes and replace learner's data with new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_build(size):\n",
    "    data = ImageDataBunch.from_folder(\n",
    "        'data-kaggle/car_data/train',\n",
    "        train='train',\n",
    "        valid_pct=.2,\n",
    "        ds_tfms=tfms,\n",
    "        size=(size, size),\n",
    "        num_workers=num_workers,\n",
    "        bs=32).normalize(imagenet_stats)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside **fit** function, we are doing a couple of things:\n",
    "\n",
    "1. Setting callbacks prior to fitting\n",
    "2. Finding the best learning rate and use three of it as an array for multiple learning rates.\n",
    "3. Fitting (both one cycle or regular fitting)\n",
    "4. Test-time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, epoch=1, one_cycle=False):\n",
    "    \n",
    "    # Callbacks\n",
    "    reduceLR = ReduceLROnPlateauCallback(model, mode='max', patience=3, factor=.9)\n",
    "    showGraph = ShowGraph(model)\n",
    "    \n",
    "    # Learning Rate\n",
    "    model.lr_find()\n",
    "    model.recorder.plot(suggestion=True)\n",
    "    lr = model.recorder.min_grad_lr\n",
    "    min_grad_lr = (lr/100, lr/10, lr)\n",
    "    \n",
    "    # Fit\n",
    "    if one_cycle == True:\n",
    "        model.fit_one_cycle(epoch, min_grad_lr, callbacks=[reduceLR, showGraph])\n",
    "    \n",
    "    else:\n",
    "        model.fit(epoch, min_grad_lr, callbacks=[reduceLR, showGraph])\n",
    "        \n",
    "    # Test-time Augmentation\n",
    "    learn.purge()\n",
    "    accuracy(*model.TTA())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_size(model, size=224):\n",
    "    data = data_build(size)\n",
    "    learn.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(\n",
    "    data_224, \n",
    "    model, \n",
    "    ps=0.1,\n",
    "    bn_final=True,\n",
    "    pretrained=True,\n",
    "    opt_func=AdamW,\n",
    "    metrics=[accuracy, error_rate]).mixup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 224 x 224px on 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_224 = data_build(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(learn, 3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 280 * 280px on 6 cyclical epochs (prone to removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_size(learn, 280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(learn, 4, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 336 * 336px on 4 cyclical epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_size(learn, 336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(learn, 4, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 400 * 400 on 4 cyclical epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_size(learn, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(learn, 4, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on test data\n",
    "\n",
    "For testing on test data, make sure each labels are separated by folders, otherwise the current code will not work. Here are the steps taken to validate test data:\n",
    "\n",
    "1. Change image size to 400 * 400\n",
    "2. Set batch size to 32\n",
    "3. Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfms = get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = ImageDataBunch.from_folder(\n",
    "    'data-kaggle/car_data/test',\n",
    "    valid_pct=0,\n",
    "    ds_tfms=test_tfms,\n",
    "    size=(460, 460),\n",
    "    num_workers=8,\n",
    "    bs=32).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results printed after the validation has finished are (in order):\n",
    "\n",
    "1. Loss\n",
    "2. Accuracy\n",
    "3. Error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.validate(data_test.train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you! 🙏"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
